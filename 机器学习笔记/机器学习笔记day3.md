###理解单变量线性回归
什么是线性回归

理解什么是代价函数，线性回归的代价函数是什么
```
h(x) = a*x + b;
J(a,b) = (1/2*m) * sum((h(x)-J(a,b))^2 .....)
```
对J(a,b)求最小值

平方差代价函数的直观理解

等高图
等高线图

碗装图像 ，导数的导数

需要一个高效算法自动寻找  代价函数最小值对应的a，b



什么是梯度下降，自己组织语言进行描述

梯度下降时  各个参数需要同步更新

梯度下降时 相同学习率的情况下 移动幅度会越来越小。
陡峭的曲线下移动一点点 斜率就会出现很大的变化，而在曲线平稳的地方移动一点，斜率的变化就微乎其微


结合平方差代价函数 和 梯度下降 理解 线性回归


推导出 代价函数的偏导数
![4f80108ebbb6707d39b7a6da4d2a7a4e.png](http://youyang321.cn-hangzhou.oss.aliyun-inc.com/machinelearn/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E5%81%8F%E5%AF%BC%E6%95%B0.jpg?OSSAccessKeyId=LTAIsFJc1qXg3VGA&Expires=1544098229&Signature=5NxEVjANptyLJJNmIta9Z4cAC78%3D)



线性回归的偏导数 是 一个凸函数
只有一个最优解

batch梯度下降和 非batch梯度下降的区别
是否每次都遍历计算了所有数据


直接通过代数 求 代价函数的最小值
正规方程组方法
但梯度下降可以用到更大数据量的问题上，而且 更具有通用性



联合概率分布：
多个变量的事件同时发生的概率。
写为  P(x=A,y=b)

条件概率：
在事件B 发生时  事件A 发生的概率。这种概率叫做条件概率
P(x=A|y=B) = P(x=A,y=b)/P(y=B)
只有在P(y=B)>0 时有意义



矩阵乘法
AxB
矩阵A（m x n） 乘以矩阵B(n x o)的每一列 
等同于 m个n维向量 乘以n维 向量，得到m个数字 ，组成了新的m维向量
这个过程持续o 次。最终得到了o个m维向量，
最终结果就是 m行o列的 新矩阵

矩阵乘法的特性
1.不符合交换律  
mxn矩阵 乘以 nxm矩阵 得到的是 mxm
nxm矩阵 乘以 mxn矩阵 得到的是nxn矩阵
两者大部分情况下 维度都不同
2.符合结合律
3.任何矩阵乘A以 单位矩阵 I 都等于A


矩阵的逆 和矩阵的转置
类似于实数中的倒数
3 必定有一个倒数1/3  与其相乘使得结果为1  （0除外）

那么矩阵的倒数是什么
矩阵的逆被 当做矩阵的倒数， 但是矩阵与矩阵相乘 是不可能为1的，因为他们的结果是一个
矩阵。
所以定义 的是矩阵与 矩阵的逆相乘 得到的是 单位矩阵（扮演1的角色）。

 只有方阵才有逆矩阵
 知道一个矩阵，求他的逆矩阵，一般通过软件去求解
 
 不存在逆矩阵的 矩阵被称为 奇异矩阵 或者 退化矩阵
 
 
 矩阵A （mxn）的转置
 相当于A的第一行作为新矩阵的第一列
 A的第二行作为新矩阵的第二列，以此类推
 新矩阵就是A的 转置
 新矩阵为n行m列
 A的x行y列的元素 等于  转置矩阵的y行x列
 
 
 
 











