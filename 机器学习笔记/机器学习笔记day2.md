####机器学习的定义
我个人理解，机器学习某种程度上可以看成是一门数据处理+统计算法 的科学。对于已有的数据进行预处理，然后把处理好的已知数据丢给计算机 ，让计算机通过算法去学习已知数据的隐藏逻辑， 并从数据中提取特征。最终目的是让计算机 可以用学会的特征去处理未知的数据。

而计算机在通过算法和数据学习时 又分两种情况：
######1.计算机每学习一次 都会获得反馈 知道这次处理的正确答案，并作出矫正，让自己的处理能够靠近正确答案。 这种被称为监督学习（支持向量机，核函数，神经网络）

######2.计算机不知道自己做的是对还是错，需要在已知数据中自己寻找规律，并进行分类。这种被称为非监督学习（聚类，降维，推荐系统）。 研究的方向例如：星系形成理论，音频分离，新闻分类


在讲到监督学习时 ，常常会用到 房价预测，乳腺癌预测这些例子。
搜集房价和房屋相关的特征，然后给机器进行分析，最终预测出其他房子的价格。

![MacDown Screenshot](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/raw/master/images/4f80108ebbb6707d39b7a6da4d2a7a4e.png)


这种方式又称之为回归，后面还会提到线性回归，逻辑回归等等。 第一次听到这个术语的人估计会有点懵。即使很多专门做机器学习的人可能也不太清楚回归这个术语的来历。

其实这个词最早是来源于一项研究：
“回归”是由英国著名生物学家兼统计学家高尔顿(Francis Galton,1822～1911.生物学家达尔文的表弟)在研究人类遗传问题时提出来的。为了研究父代与子代身高的关系，高尔顿搜集了1078对父亲及其儿子的身高数据。他发现总的趋势是父亲的身高增加时，儿子的身高也倾向于增加。但是，高尔顿对试验数据进行了深入的分析，发现了一个很有趣的现象：当父亲高于平均身高时，他们的儿子身高比他更高的概率要小于比他更矮的概率；父亲矮于平均身高时，他们的儿子身高比他更矮的概率要小于比他更高的概率。它反映了一个规律，即这两种身高父亲的儿子的身高，有向他们父辈的平均身高回归的趋势。对于这个一般结论的解释是:大自然具有一种约束力，使人类身高的分布相对稳定而不产生两极分化，这就是所谓的回归效应。

这也就是预测的本质，当机器通过对已知数据的学习找到了那条回归线，那么就可以通过判断未知数据和回归线的关系来预测结果。



提到无监督学习 ，最典型的是聚类
聚类算法和无监督学习算法同样还用在很多其它的问题上

![MacDown Screenshot](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/raw/master/images/903868fb76c706f1e2f96d8e26e0074e.png)

其中就有基因学的理解应用。一个DNA微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）……

所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。




对于少量特征的学习可以通过 坐标系来绘图表示，但是对于大量特征的数据进行处理时就需要一些别的方法：



